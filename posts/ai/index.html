<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=generator content="Hugo 0.91.2">
<title> AI | Alexander Saavedra </title>
<meta name=description content="A simple and concise hugo theme.">
<link rel=stylesheet href=https://awsaavedra.com/css/simpleness.css>
<link rel=canonical href=https://awsaavedra.com/posts/ai/>
<link rel=alternate type=application/rss+xml href title="Alexander Saavedra">
<link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css rel=stylesheet>
</head>
<body class=container>
<nav class=navigation>
<div class=nav-left>
<div class="nav-item nav-title">
<a href=https://awsaavedra.com/> Alexander Saavedra</a>
</div>
<div class="nav-item nav-menu">
<a href=/documentation/> Documentation</a>
<a href=/about/> About</a>
<a href=/resume/> Resume</a>
<a href=/projects/> Projects</a>
<a href=/quotes/> Quotes</a>
<a href> </a>
</div>
</div>
<div class="nav-item nav-right fontawesome">
<a href=https://github.com/awsaavedra target=_blank>
<i title=GitHub class="fab fa-github"></i>
</a>
<a href=https://linkedin.com/in/awsaavedra target=_blank>
<i title=LinkedIn class="fab fa-linkedin"></i>
</a>
<a href=https://awsaavedra.com/index.xml target=_blank>
<i title=RSS class="fas fa-rss"></i>
</a>
</div>
</nav>
<article class=post>
<header class=post-header>
<h1 style=text-align:center>AI</h1>
<div class=post-metadata>
<time datetime=2025-02-28T16:39:08-08:00>Originally posted February 28, 2025</time> &nbsp;
<div class=post-lastmod>
<time datetime=2025-03-19T20:02:14-08:00>
Update on March 19, 2025
</time>
<p></p>
</div>
<i class="far fa-clock"></i>
11 min
10 s
&nbsp;
</div>
</header>
<div class=post-text>
<p>We refer to the question: What sort of creature man’s next successor in the supremacy of the earth is likely to be.
We have often heard this debated; but it appears to us that we are ourselves creating our own successors;
we are daily adding to the beauty and delicacy of their physical organisation;
we are daily giving them greater power and supplying by all sorts of ingenious contrivances that self-regulating,
self-acting power which will be to them what intellect has been to the human race.
In the course of ages we shall find ourselves the inferior race.
&mldr;
Day by day, however, the machines are gaining ground upon us;
day by day we are becoming more subservient to them; more men are daily
bound down as slaves to tend them, more men are daily devoting the energies of
their whole lives to the development of mechanical life.
The upshot is simply a question of time, but that the time will come when the machines
will hold the real supremacy over the world and its inhabitants is what
no person of a truly philosophic mind can for a moment question.</p>
<p>~ Darwin among the Machines by Cellarius (Samuel Butler)</p>
<p>I remember reading this quote and wondering when this was written.</p>
<p>Can you guess without looking this up? At the end of this I&rsquo;ll tell you.</p>
<p>When dealing with AI timelines it&rsquo;s been a wild ride realizing back in 2007 that the
age of machines was upon us. Whether we will be economically relevant as a species is
a fascinating subject with many perspectives.</p>
<p>As we get closer to the singularity many questions will be asked about science, philosophy, and our economic relevancy as a species.
The <strong>singularity</strong> is a point at which is when technological progress cannot be understood
by current human mind since it is progressing so quickly.
The only way to get around
this is to increase our speed of understanding by enhancing our own intelligence
via numerous methods that will expand our neo-cortex many fold.</p>
<p>Humans are becoming cyborgs. What&rsquo;s the difference between an android and cyborg
is not as interesting of a question as whether all computations can be equivalent
regardless of the hardware performing it. The mind can be viewed as a series of patterns
and I view patternism as the best attempt as understanding these patterns.</p>
<p>In addition, the type of hardware running these patterns is largely irrelevant.
The reason why is because if these computations are equivalent then the substance of the
computation is the same.
This view is called <strong>computational equivalence</strong> in which
as long as both systems can perform the same computations then they&rsquo;re equivalent.</p>
<p>I&rsquo;m not going to try to convince the reader that humans are unique in our mental processes
quiet the opposite.
I would argue we inhabit an interesting branch of the evolutionary tree
however it is definitely possible to replicate in a machine mind.</p>
<h1 id=objections-to-these-ideas>Objections to these ideas</h1>
<p><img src=/ai/only-humans.png alt="Only Human" title="Only human"></p>
<p>There are numerous objections to all of these ideas but one is that these computations
human brains do is NOT equivalent to AI.
This is completely false from a technical perspective.
If the computations are indistinguishable from one another in terms of function
how then can we know the substance of the computation is not equivalent?
Performing a deeper equality test gets harder and harder as you go down this chain of reasoning.</p>
<p>Another one is the AIs are not embodied, which is a valid criticism.
How long will this fact stay true though?
Not long as robotics advanced.</p>
<p>The other arguments break down to what Scott Aaronson called &ldquo;Justaism&rdquo; arguments like
the following:</p>
<pre><code>1. AI is just a stoicastic parrot
2. AI is just a next work completion device
</code></pre>
<p>I could go on but as Scott states &ldquo;what the justaism arguers always fail to realize
is all these arguments apply to us (humans)&rdquo;.</p>
<p>A very historically minded objection would be that the field of AI
made this same claim awhile ago and got it extremely wrong which I will address below.</p>
<h1 id=ai-winter-of-the-80s>AI Winter of the 80s</h1>
<p>“Technologically, as I have argued earlier, machines will be capable, within twenty years, of doing any work that a man can do. Economically,
men will retain their greatest comparative advantage in jobs that require flexible manipulation of those parts of the environment
that are relatively rough—some forms of manual work, control of some kinds of machinery (e.g., operating earth-moving equipment),
some kinds of nonprogrammed problem solving, and some kinds of service activities
where face-to-face human interaction is of the essence.” ~ 1960, The New Science of Management Decision by Herbert A. Simon</p>
<p>Back in the 70s and 80s people were wrongly predicting that the AIs would surpass humans that decade.</p>
<p>The two schools of research were expert systems and the connectionist school.
The connectionists used the brain for inspiration and the expert systems used more formal logic for inspiration.
From the Stanford Encyclopedia of philosophy it states that
“Connectionism is a movement in cognitive science that hopes to explain intellectual abilities
using artificial neural networks (also known as “neural networks” or “neural nets”).”
Expert systems use formal logic structures that proved to be very brittle.
One of the most famous expert systems was a set of incredibly nested and
convoluted conditional statements e.g. &ldquo;if else&rdquo; (spaghetti code?) that become so hard to maintain almost all
changes made after a certain point broke the program.</p>
<p>The majority of universities and research groups bet on the expert systems side and some on the connectionist side.
The lack of progress on both fronts created the AI winter.
The few places that did continue on the connectionist side eventually bore fruit of course.
Numerous factors contributed to this but the most obvious was overpromising and under delivering.
Especially since numerous researchers expected a generally intelligent system by 1980 or so.</p>
<p>These connectionist researchers are now incredibly famous such as Geoffrey Hinton.
Places like University of Toronto who produced the likes of Ilya Sutskever stuck it out when connectionism seemed implausible.</p>
<p>The opposite of “this time is different" is “it is always the same."
Sometimes things are indeed different, <strong>my central claim is that this time is indeed different</strong>.</p>
<p>People measure things by time instead of events.
This is a bad idea when to use time based terms “sometimes a century can happen in a day."
The amount of paradigm shifting events will increase. Buckle up.
A better measurement is change which is the the number of events happening over a given time interval.</p>
<p>Humans' intuitions are linear but information technology is exponential.
When people project the growth they are deceived at first by the exponential as
it looks flat or barely growing but increases drastically.</p>
<h1 id=will-machines-be-conscious>Will machines be conscious?</h1>
<p>This is a complex philosophical topic and I will only state a couple things.</p>
<ol>
<li>
<p>The only completely knowable fact to you is that you&rsquo;re conscious</p>
</li>
<li>
<p>It is unknowable with present technology to know if another being is conscious. It&rsquo;s just an assumption others being are albeit a good one from a practical perspective!</p>
</li>
<li>
<p>We should use the same standards of evidence we use for other people, animals, etc. to
apply to AI to decide it is conscious.</p>
<ul>
<li>AI tools like large language models have passed the turing test already and
almost no one paid attention</li>
</ul>
</li>
</ol>
<h1 id=how-long-until-we-get-machines-as-smart-as-us>How long until we get machines as smart as us?</h1>
<p><img src=/ai/benchmarks.png alt=benchmarks title=Benchmarking></p>
<p>That&rsquo;s the real question that matters, the possibilities is inevitable assuming we keep
progressing and I&rsquo;m fairly certain it will happen in the next 5 year.
As smart as an average person as least in terms of software operations.</p>
<p>Since it is an exponential trend it will surpass the whole of humanity as some point
and what then?
I don&rsquo;t know, but very soon in the next 10-20 years at most, I think 2040 to 2045 is conservative.
It&rsquo;s unclear on the embodied piece of this though, it is looking like robotics may be behind.</p>
<p>I am sidestepping one major thing though, what is intelligence?
This is a rather difficult question if you allow yourself to be puzzled by the deeper
and subtle parts of what this question asks.</p>
<h1 id=science-fiction-and-potential-science-fact-scenarios>Science fiction and potential science fact scenarios</h1>
<p>I wrote a blog post about perspectives on progress in which I covered possible
future scenarios humans may face.
The major one we are currently facing
is one in which bits, as opposed to atoms, are experiencing exponential progress.
At this point it is an undeniable fact that machine intelligence is progressing
faster than most expected.
Back in 1999 when Ray Kurzweil wrote The Age of Spiritual
Machines and predict artificial general intelligence by 2029 the AI community got
together and came up with 100+ year timeline to reach AGI.
His position was highly controversial but
he was clearly potentially producing <strong>idea alpha</strong> much like I discussed previously.</p>
<p>Many possibilities exist but one of them is from the short SciFi story The Machine Stops
by E.M. Forster. In this world we are completely depend on the machines for everything.</p>
<p>Another one of the Age of Em by Rob Hanson is which the primary humans who are
still economically relevant are synthetic humans who exist in digital cities or
completely virtually.</p>
<p>Another short story is I, Robot.
This was also made into a movie in which the machines
decided the maximally efficient solution for humans to remain unharmed was to keep
them isolated and under a panopticon. A panopticon is a prison in which everyone
is being monitored at all times and disciplined for any transgression.</p>
<p>The Positronic Man by Asimov is story covering which covers numerous topics most importantly
to me the chauvinism of humanity. It was later turned into the movie Bicenntial Man with Robin Williams.</p>
<p>As Robert Sapolsky said with extreme sarcasm &ldquo;For all creatures are unique, but humans
are the unique-est.&rdquo;
What Sapolsky is getting at is that humans have the delusion they are the most
important organism from an objective and cosmic perspective when in fact they are not.
There is no objective reason to say this is the case.
It is a case of value constellations in which we&rsquo;ve selected our own biased
value system to decided that a certain configuration of values matter most.
Why? Simply because they matter the most to us. Pure conceited arguments
for our own perspective. If bees in our position and highly intelligent
honey making would probably be high on the list. You may chuckle but
it is equally as ridiculous to select whatever constellation of values you&rsquo;ve
chosen.
All values are contextual and instrumental to the goals used.
There may be universal values but that&rsquo;s a tough one to argue for.</p>
<p>There are numerous other books and movies on the topic, but
many I think do not lay out plausible future possibilities.
I will name one more I liked Do Robots dream of electric Sheep?</p>
<h1 id=what-do-you-see-in-the-sloggoth>What do you see in the Sloggoth?</h1>
<p>There are many descriptions of the concept of a Sloggoth, my favorite is this one:</p>
<p>&ldquo;It was a terrible, indescribable thing vaster than any subway train—a shapeless congeries of protoplasmic bubbles,
faintly self-luminous, and with myriads of temporary eyes forming and un-forming as pustules of greenish light all over
the tunnel-filling front that bore down upon us, crushing the frantic penguins and slithering
over the glistening floor that it and its kind had swept so evilly free of all litter.&rdquo;</p>
<p>— H. P. Lovecraft, At the Mountains of Madness</p>
<p><img src=/ai/rorschach-sloggoth.png alt=rorscach title=rorschach></p>
<p>AI is often referred to as a sloggoth.</p>
<p>Besides being supposedly menacing it is a hodge podge of things while being nothing in particular.
Similar to a rorschach test you&rsquo;re making meaning out of a muddled image.
People see what their prejudices allow and create meaning everywhere there.</p>
<h1 id=resources-for-learning-more-about-machine-learning>Resources for learning more about Machine Learning</h1>
<p>I am very hesitant to add articles and websites since staying fresh
on these topics is difficult but I&rsquo;ll try my best to add things that won&rsquo;t go stale.</p>
<ol>
<li>
<p>Podcasts:</p>
<p>a. Lex Fridman Machine Learning podcasts are solid</p>
<p>b. Machine Learning Street Talk</p>
<p>c. No Priors: Artificial Intelligent | Technology | Startups</p>
<p>d. Dwarkesh Patel&rsquo;s Lunar Society</p>
<p>e. Moonshots with Peter Diamandis</p>
<p>f. The Cognitive Revolution | AI Builders, Researchers, and Live Player Analysis</p>
<p>g. Foresight Institute Podcast (sometimes)</p>
<p>h. Win-Win with Liv Boeree (mostly game theory stuff though)</p>
</li>
<li>
<p>Tools: I am not going to attempt this just look at benchmarks that
come out and decide for yourself using them. Use cases to pay attention to:</p>
<p>a. Coding</p>
<p>b. Search</p>
<p>c. Image generation</p>
<p>d. Ideation</p>
<p>e. large action models performing basic tasks for you</p>
</li>
<li>
<p>Newsletters:</p>
<p>a. <a href=https://alphasignal.ai/>https://alphasignal.ai/</a></p>
<p>b. There are others but a lot of them are low signal, mostly noise</p>
</li>
<li>
<p>Foundational Books:</p>
<p>a. Deep Learning: Foundations and Concepts 2024th Edition by Christopher M. Bishop and Hugh Bishop</p>
<p>b. Deep Learning by Ian Goodfellow</p>
<p>c. Mathematics for Machine Learning by Marc Peter Deisenroth A Aldo Faisal Cheng and Soon Ong</p>
<p>d. Deep Learning with Python by Francois Chollet</p>
<p>e. Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig
Note: Both of these authors you should read their stuff. It&rsquo;s fantastic</p>
<p>f. Unsupervised Learning: Foundations of Neural Computation by Geoffrey Hinton and Sejnowski
One of the founders of the field from University of Toronto.</p>
</li>
</ol>
<h1 id=machine-learning-people>Machine Learning people</h1>
<p>Someones probably put together a more comprehensive list e.g. <a href=https://time.com/collection/time100-ai-2024/>https://time.com/collection/time100-ai-2024/</a>
than me but I&rsquo;m going to attempt to add a shorter list here in order of need to know.</p>
<ol>
<li>
<p>Alex Krizhevsky, more information here: <a href="https://news.ycombinator.com/item?id=42505519">https://news.ycombinator.com/item?id=42505519</a></p>
</li>
<li>
<p>Scott Aaronson can be found here: <a href=https://scottaaronson.blog/>https://scottaaronson.blog/</a></p>
</li>
<li>
<p>Stuart Russell <a href=https://en.wikipedia.org/wiki/Stuart_J._Russell>https://en.wikipedia.org/wiki/Stuart_J._Russell</a></p>
</li>
<li>
<p>Charles Isbell</p>
</li>
<li>
<p>Demis Hassabis Deep Mind founder</p>
</li>
<li>
<p>Dario Amodei</p>
</li>
<li>
<p>Yoshua Bengio</p>
</li>
<li>
<p>Andrew Ng</p>
</li>
<li>
<p>Francios Chollet especially his work on the ARC prize</p>
</li>
<li>
<p>Marvin Minsky <a href=https://en.wikipedia.org/wiki/Marvin_Minsky>https://en.wikipedia.org/wiki/Marvin_Minsky</a></p>
</li>
<li>
<p>Herbert A Simon <a href=https://en.wikipedia.org/wiki/Herbert_A._Simon>https://en.wikipedia.org/wiki/Herbert_A._Simon</a></p>
</li>
<li>
<p>Ian Goodfellow</p>
</li>
<li>
<p>Fei-Fei Li</p>
</li>
<li>
<p>Ray Kurzweil</p>
</li>
<li>
<p>Ilya Sutskever</p>
</li>
</ol>
<p>There are others and lots of interesting machine learning peope at companies.
The people I chose are mostly because of their work being relevant to me or
intersecting with me.</p>
<h1 id=when-was-the-quote-at-the-beginning-written-about-machines>When was the quote at the beginning written about machines?</h1>
<p>13 June 1863, we&rsquo;ve known for awhile machines could become smarter than we could
given their lack of biological limitations.</p>
<p>The book written on this topic is Erewhon: The Book of the Machines by Samuel Butler.</p>
<h1 id=additional-resources>Additional Resources</h1>
<p>I did a project of building ChatGPT2, here you go: <a href=https://github.com/awsaavedra/building-an-llm-from-scratch>https://github.com/awsaavedra/building-an-llm-from-scratch</a></p>
<p>Ray Kurzweil&rsquo;s The Singularity is Near</p>
<p><a href="https://www.safe.ai/blog/humanitys-last-exam?trk=feed_main-feed-card_feed-article-content">https://www.safe.ai/blog/humanitys-last-exam?trk=feed_main-feed-card_feed-article-content</a></p>
<p><a href=https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is>Why Alignment between humans and AI matters</a></p>
<p><a href=https://arcprize.org/>https://arcprize.org/</a> for testing whether an AI is as intelligent as a person.</p>
<pre><code>- just don't shift the goal post after it passes
</code></pre>
<p><a href=https://situational-awareness.ai/>https://situational-awareness.ai/</a> A good comprehensive outline of the direction we are headed.</p>
<p><a href=https://www.lesswrong.com/posts/q5beZEfdoNsjL6TWm/a-problem-with-patternism>https://www.lesswrong.com/posts/q5beZEfdoNsjL6TWm/a-problem-with-patternism</a></p>
<p><a href="https://scottaaronson.blog/?p=7784">https://scottaaronson.blog/?p=7784</a></p>
<pre><code>https://github.com/Zak-Hussain/againstJustaism 
</code></pre>
<p><a href=https://www.amazon.com/Hidden-Pattern-Patternist-Philosophy-Mind/dp/1581129890>https://www.amazon.com/Hidden-Pattern-Patternist-Philosophy-Mind/dp/1581129890</a></p>
<p>Look into AI <code>Rant mode</code>
<a href=https://en.wikipedia.org/wiki/Darwin_among_the_Machines>https://en.wikipedia.org/wiki/Darwin_among_the_Machines</a></p>
<p><a href=https://ai-timeline.org/>https://ai-timeline.org/</a> ai timeline of the past 10 years in pretty high resolution</p>
<p><a href=https://www.simonsfoundation.org/event/the-next-great-scientific-theory-is-hiding-inside-a-neural-network>https://www.simonsfoundation.org/event/the-next-great-scientific-theory-is-hiding-inside-a-neural-network</a><br>
AI will fuel scientific discovery massively</p>
</div>
<footer class=post-footer>
<div class=post-tags>
<i class="fas fa-tags"></i>
<a href=/tags/philosophy>philosophy</a>
&nbsp;
<a href=/tags/software>software</a>
&nbsp;
</div>
<div class=related-posts>
<h4>Related Posts</h4>
<i class="fas fa-paperclip"></i>
<a href=/posts/idea-alpha/>Seeking Idea Alpha</a>
<br>
<i class="fas fa-paperclip"></i>
<a href=/posts/status-quo/>Status Quo</a>
<br>
<i class="fas fa-paperclip"></i>
<a href=/posts/enterprising-investor/>Enterprising Investor</a>
<br>
</div>
<div class=post>
<h1 class=post-title>Subscribe</h1>
<p>I hope you enjoyed reading my blog!</p>
<p>Sign up for my <a href=https://tinyletter.com/awsaavedra>email newsletter.</a></p>
</div>
</footer>
<div class=comments>
<div class=comments>
</div>
</div>
</article>
<div class=foot>
&copy; 2025 &#183;
<a href=#><i class="fas fa-chevron-up"></i></a>
</div>
</body>
<script src=/js/lazyload.min.js></script>
<script>var lazyImage=new LazyLoad({container:document.getElementById('article')})</script>
</html>