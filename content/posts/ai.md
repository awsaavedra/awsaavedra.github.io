---
title: "AI"
date: 2025-02-28T16:39:08-08:00
lastmod: 2026-02-27T00:00:00-08:00
author: Alexander Saavedra
tags: [philosophy, software]
draft: false
---
We refer to the question: What sort of creature man’s next successor in the supremacy of the earth is likely to be. 
We have often heard this debated; but it appears to us that we are ourselves creating our own successors; 
we are daily adding to the beauty and delicacy of their physical organisation; 
we are daily giving them greater power and supplying by all sorts of ingenious contrivances that self-regulating, 
self-acting power which will be to them what intellect has been to the human race. 
In the course of ages we shall find ourselves the inferior race.
...
Day by day, however, the machines are gaining ground upon us; 
day by day we are becoming more subservient to them; more men are daily 
bound down as slaves to tend them, more men are daily devoting the energies of 
their whole lives to the development of mechanical life. 
The upshot is simply a question of time, but that the time will come when the machines 
will hold the real supremacy over the world and its inhabitants is what 
no person of a truly philosophic mind can for a moment question.

~ Darwin among the Machines by Cellarius (Samuel Butler)

I remember reading this quote and wondering when this was written.

Can you guess without looking this up? At the end of this I'll tell you.

When dealing with AI timelines it's been a wild ride realizing back in 2007 that the 
age of machines was upon us. Whether we will be economically relevant as a species is 
a fascinating subject with many perspectives.

As we get closer to the singularity many questions will be asked about science, philosophy, and our economic relevancy as a species. 
The **singularity** is a point at which is when technological progress cannot be understood
by current human mind since it is progressing so quickly. 
The only way to get around 
this is to increase our speed of understanding by enhancing our own intelligence 
via numerous methods that will expand our neo-cortex many fold.

Humans are becoming cyborgs. What's the difference between an android and cyborg 
is not as interesting of a question as whether all computations can be equivalent
regardless of the hardware performing it. The mind can be viewed as a series of patterns 
and I view patternism as the best attempt as understanding these patterns.

In addition, the type of hardware running these patterns is largely irrelevant.
The reason why is because if these computations are equivalent then the substance of the 
computation is the same. 
This view is called **computational equivalence** in which
as long as both systems can perform the same computations then they're equivalent.

I'm not going to try to convince the reader that humans are unique in our mental processes
quiet the opposite. 
I would argue we inhabit an interesting branch of the evolutionary tree
however it is definitely possible to replicate in a machine mind.

# Objections to these ideas
![Only Human](/ai/only-humans.png "Only human")


There are numerous objections to all of these ideas but one is that these computations 
human brains do is NOT equivalent to AI. 
This is completely false from a technical perspective.
If the computations are indistinguishable from one another in terms of function 
how then can we know the substance of the computation is not equivalent? 
Performing a deeper equality test gets harder and harder as you go down this chain of reasoning.

Another one is the AIs are not embodied, which is a valid criticism. 
How long will this fact stay true though? 
Not long as robotics advanced.

The other arguments break down to what Scott Aaronson called "Justaism" arguments like
the following:

    1. AI is just a stoicastic parrot
    2. AI is just a next work completion device

I could go on but as Scott states "what the justaism arguers always fail to realize 
is all these arguments apply to us (humans)". 

A very historically minded objection would be that the field of AI 
made this same claim awhile ago and got it extremely wrong which I will address below.

# AI Winter of the 80s
“Technologically, as I have argued earlier, machines will be capable, within twenty years, of doing any work that a man can do. Economically, 
men will retain their greatest comparative advantage in jobs that require flexible manipulation of those parts of the environment 
that are relatively rough—some forms of manual work, control of some kinds of machinery (e.g., operating earth-moving equipment), 
some kinds of nonprogrammed problem solving, and some kinds of service activities 
where face-to-face human interaction is of the essence.” ~ 1960, The New Science of Management Decision by Herbert A. Simon

Back in the 70s and 80s people were wrongly predicting that the AIs would surpass humans that decade. 

The two schools of research were expert systems and the connectionist school. 
The connectionists used the brain for inspiration and the expert systems used more formal logic for inspiration. 
From the Stanford Encyclopedia of philosophy it states that 
“Connectionism is a movement in cognitive science that hopes to explain intellectual abilities 
using artificial neural networks (also known as “neural networks” or “neural nets”).” 
Expert systems use formal logic structures that proved to be very brittle. 
One of the most famous expert systems was a set of incredibly nested and 
convoluted conditional statements e.g. "if else" (spaghetti code?) that become so hard to maintain almost all 
changes made after a certain point broke the program.

The majority of universities and research groups bet on the expert systems side and some on the connectionist side.
The lack of progress on both fronts created the AI winter. 
The few places that did continue on the connectionist side eventually bore fruit of course.
Numerous factors contributed to this but the most obvious was overpromising and under delivering. 
Especially since numerous researchers expected a generally intelligent system by 1980 or so.

These connectionist researchers are now incredibly famous such as Geoffrey Hinton. 
Places like University of Toronto who produced the likes of Ilya Sutskever stuck it out when connectionism seemed implausible. 

The opposite of “this time is different" is “it is always the same." 
Sometimes things are indeed different, **my central claim is that this time is indeed different**.

People measure things by time instead of events. 
This is a bad idea when to use time based terms “sometimes a century can happen in a day." 
The amount of paradigm shifting events will increase. Buckle up.
A better measurement is change which is the the number of events happening over a given time interval.

Humans' intuitions are linear but information technology is exponential. 
When people project the growth they are deceived at first by the exponential as
it looks flat or barely growing but increases drastically.

# Will machines be conscious? 

This is a complex philosophical topic and I will only state a couple things.

1. The only completely knowable fact to you is that you're conscious
2. It is unknowable with present technology to know if another being is conscious. It's just an assumption others being are albeit a good one from a practical perspective! 

3. We should use the same standards of evidence we use for other people, animals, etc. to 
apply to AI to decide it is conscious. 

    - AI tools like large language models have passed the turing test already and 
    almost no one paid attention


# How long until we get machines as smart as us?

![benchmarks](/ai/benchmarks.png "Benchmarking")

That's the real question that matters, the possibilities is inevitable assuming we keep 
progressing and I'm fairly certain it will happen in the next 5 year. 
As smart as an average person as least in terms of software operations. 

Since it is an exponential trend it will surpass the whole of humanity as some point
and what then? 
I don't know, but very soon in the next 10-20 years at most, I think 2040 to 2045 is conservative.
It's unclear on the embodied piece of this though, it is looking like robotics may be behind.

I am sidestepping one major thing though, what is intelligence? 
This is a rather difficult question if you allow yourself to be puzzled by the deeper
and subtle parts of what this question asks.

# Science fiction and potential science fact scenarios
I wrote a blog post about perspectives on progress in which I covered possible 
future scenarios humans may face. 
The major one we are currently facing 
is one in which bits, as opposed to atoms, are experiencing exponential progress.
At this point it is an undeniable fact that machine intelligence is progressing
faster than most expected. 
Back in 1999 when Ray Kurzweil wrote The Age of Spiritual
Machines and predict artificial general intelligence by 2029 the AI community got
together and came up with 100+ year timeline to reach AGI. 
His position was highly controversial but
he was clearly potentially producing **idea alpha** much like I discussed previously.

Many possibilities exist but one of them is from the short SciFi story The Machine Stops 
by E.M. Forster. In this world we are completely depend on the machines for everything.

Another one of the Age of Em by Rob Hanson is which the primary humans who are 
still economically relevant are synthetic humans who exist in digital cities or 
completely virtually.

Another short story is I, Robot. 
This was also made into a movie in which the machines 
decided the maximally efficient solution for humans to remain unharmed was to keep 
them isolated and under a panopticon. A panopticon is a prison in which everyone 
is being monitored at all times and disciplined for any transgression.

The Positronic Man by Asimov is story covering which covers numerous topics most importantly
to me the chauvinism of humanity. It was later turned into the movie Bicenntial Man with Robin Williams.

As Robert Sapolsky said with extreme sarcasm "For all creatures are unique, but humans
are the unique-est." 
What Sapolsky is getting at is that humans have the delusion they are the most 
important organism from an objective and cosmic perspective when in fact they are not.
There is no objective reason to say this is the case. 
It is a case of value constellations in which we've selected our own biased 
value system to decided that a certain configuration of values matter most. 
Why? Simply because they matter the most to us. Pure conceited arguments
for our own perspective. If bees in our position and highly intelligent 
honey making would probably be high on the list. You may chuckle but 
it is equally as ridiculous to select whatever constellation of values you've
chosen. 
All values are contextual and instrumental to the goals used.
There may be universal values but that's a tough one to argue for.


There are numerous other books and movies on the topic, but
many I think do not lay out plausible future possibilities.
I will name one more I liked Do Robots dream of electric Sheep? 

# What do you see in the Sloggoth?

There are many descriptions of the concept of a Sloggoth, my favorite is this one:

"It was a terrible, indescribable thing vaster than any subway train—a shapeless congeries of protoplasmic bubbles, 
faintly self-luminous, and with myriads of temporary eyes forming and un-forming as pustules of greenish light all over 
the tunnel-filling front that bore down upon us, crushing the frantic penguins and slithering 
over the glistening floor that it and its kind had swept so evilly free of all litter."

— H. P. Lovecraft, At the Mountains of Madness

![rorscach](/ai/rorschach-sloggoth.png "rorschach")

AI is often referred to as a sloggoth.

Besides being supposedly menacing it is a hodge podge of things while being nothing in particular.
Similar to a rorschach test you're making meaning out of a muddled image.
People see what their prejudices allow and create meaning everywhere there.

# Resources for learning more about Machine Learning

I am very hesitant to add articles and websites since staying fresh 
on these topics is difficult but I'll try my best to add things that won't go stale.

1. Podcasts: 

    a. Lex Fridman Machine Learning podcasts are solid

    b. Machine Learning Street Talk

    c. No Priors: Artificial Intelligent | Technology | Startups

    d. Dwarkesh Patel's Lunar Society

    e. Moonshots with Peter Diamandis

    f. The Cognitive Revolution | AI Builders, Researchers, and Live Player Analysis

    g. Foresight Institute Podcast (sometimes)

    h. Win-Win with Liv Boeree (mostly game theory stuff though)

    i. https://theinnermostloop.substack.com/

6. Tools: I am not going to attempt this just look at benchmarks that 
come out and decide for yourself using them. Use cases to pay attention to:

    a. Coding

    b. Search

    c. Image generation

    d. Ideation 

    e. large action models performing basic tasks for you

7. Newsletters: 

    a. https://alphasignal.ai/

    b.  There are others but a lot of them are low signal, mostly noise

8. Foundational Books:

    a. Deep Learning: Foundations and Concepts 2024th Edition by Christopher M. Bishop and Hugh Bishop

    b. Deep Learning by Ian Goodfellow

    c. Mathematics for Machine Learning by Marc Peter Deisenroth A Aldo Faisal Cheng and Soon Ong

    d. Deep Learning with Python by Francois Chollet

    e. Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig
        Note: Both of these authors you should read their stuff. It's fantastic

    f. Unsupervised Learning: Foundations of Neural Computation by Geoffrey Hinton and Sejnowski
        One of the founders of the field from University of Toronto. 

    g. What's ChatGPT doing and how does it work? by Stephen Wolfram

# Machine Learning people

Someones probably put together a more comprehensive list e.g. https://time.com/collection/time100-ai-2024/
than me but I'm going to attempt to add a shorter list here in order of need to know.


1. Alex Krizhevsky, more information here: https://news.ycombinator.com/item?id=42505519

2. Scott Aaronson can be found here: https://scottaaronson.blog/

3. Stuart Russell https://en.wikipedia.org/wiki/Stuart_J._Russell 

4. Charles Isbell

5. Demis Hassabis Deep Mind founder

6. Dario Amodei

7. Yoshua Bengio

8. Andrew Ng

9. Francios Chollet especially his work on the ARC prize

10. Marvin Minsky https://en.wikipedia.org/wiki/Marvin_Minsky

11. Herbert A Simon https://en.wikipedia.org/wiki/Herbert_A._Simon

12. Ian Goodfellow

13. Fei-Fei Li

14. Ray Kurzweil

15. Ilya Sutskever

There are others and lots of interesting machine learning peope at companies.
The people I chose are mostly because of their work being relevant to me or 
intersecting with me. 

# When was the quote at the beginning written about machines?
13 June 1863, we've known for awhile machines could become smarter than we could
given their lack of biological limitations.

The book written on this topic is Erewhon: The Book of the Machines by Samuel Butler.


# Additional Resources

I did a project of building ChatGPT2, here you go: https://github.com/awsaavedra/building-an-llm-from-scratch 

[What Is ChatGPT Doing … and Why Does It Work? by Stephen Wolfram](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)

    Full book can be found [here](https://www.wolfram-media.com/products/what-is-chatgpt-doing-and-why-does-it-work/)


Ray Kurzweil's The Singularity is Near

https://www.safe.ai/blog/humanitys-last-exam?trk=feed_main-feed-card_feed-article-content


[Why Alignment between humans and AI matters](https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/my-understanding-of-what-everyone-in-technical-alignment-is)

https://arcprize.org/ for testing whether an AI is as intelligent as a person.
    
    - just don't shift the goal post after it passes

https://situational-awareness.ai/ A good comprehensive outline of the direction we are headed.

https://www.lesswrong.com/posts/q5beZEfdoNsjL6TWm/a-problem-with-patternism

https://scottaaronson.blog/?p=7784  

    https://github.com/Zak-Hussain/againstJustaism 

https://www.amazon.com/Hidden-Pattern-Patternist-Philosophy-Mind/dp/1581129890

Look into AI `Rant mode`
https://en.wikipedia.org/wiki/Darwin_among_the_Machines

https://ai-timeline.org/ ai timeline of the past 10 years in pretty high resolution

https://www.simonsfoundation.org/event/the-next-great-scientific-theory-is-hiding-inside-a-neural-network
AI will fuel scientific discovery massively

https://theinnermostloop.substack.com/




